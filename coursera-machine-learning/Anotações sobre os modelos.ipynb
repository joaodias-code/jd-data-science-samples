{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODELOS de Classificação (estudos e prática realizada)\n",
    "\n",
    "#### Comparações dos modelos ####\n",
    "\n",
    "1. **KNN - Vizinho mais próximo (classificação)**\n",
    "    - KNN suporta 'non-linear solutions'.\n",
    "    - KNN é 'non-parametric'.\n",
    "    - Calcular a distância no caso de dataset com multivariáveis:\n",
    "        - Dis(x1,x2) = Math.sqrt( (x1i - x2i)² )  Obs.: x1, x2, x3.. var independentes.\n",
    "    - Normalizar os dados: como o algoritmo tem que realizar os cálculos de distância, normalizar melhora este esforço de cálculo.  \n",
    "    \n",
    "    \n",
    "2. **Decision Trees**\n",
    "    - Decision tree suporta 'non-linear solutions'.\n",
    "    - Decision tree é 'non-parametric'.\n",
    "    - Trees: calcular a entropia (quanto menor melhor).. medida de aleatoridade ou incerteza. Ou seja, quanto menos incerteza num nodo (esta mais para uma medida), fácil decidir.\n",
    "    - Information gain: cálcula o nível de certeza após split dos nodos. Comparar qual split é melhor para a árvore.\n",
    "    \n",
    "\n",
    "3. **Logistic Regression**\n",
    "    - Somente 'linear solutions'\n",
    "    - Aplicações:\n",
    "        + Prever a probabilidade de uma pessoa ter ataque de coração.\n",
    "        + Prever a mortalidade de pacientes doentes.\n",
    "        + Prever a propensão de um cliente comprar um produto ou interromper uma assinatura.\n",
    "        + Prever a probabilidade de falha de um determinado processo ou produto.\n",
    "        + Prever a probabilidade de um proprietário deixar de pagar uma hipoteca.\n",
    "        \n",
    "    \n",
    "4. **Support Vector Machine**\n",
    "    - SVM suporta 'non-linear solutions'.\n",
    "    - SVM é melhor para detectar outliers do que KNN.\n",
    "    - Aplicações:\n",
    "        + Classificação de imagens\n",
    "        + Reconhecimento de escrita a mão\n",
    "        + Tarefas de mineração de textos\n",
    "        + Detecção de spam\n",
    "        + Análise de sentimentos\n",
    "        + Classificação de genes (por causa da precisão com 'high dimensional spaces')\n",
    "    - Vantagens:\n",
    "        + Precisão para 'high-dimensional spaces'\n",
    "        + Eficiente uso de memória\n",
    "    - Desvantagens:\n",
    "        + Propenso a overfitting se o número de variáveis dependentes for maior que número de amostras.\n",
    "        + Não estima probabilidade. É concebido para classificação.\n",
    "        + Não é bom para datasets grandes.\n",
    "\n",
    "#### Métricas: ####\n",
    "- _Jaccard index_: 'metrics.accuracy_score' ou 'jaccard_similarity_score' (iguais)\n",
    "- _F1-score_ (confusion matriz): construir o gráfico\n",
    "    + Precision = TP / (TP + FP)\n",
    "    + Recall = TP / (TP + FN)\n",
    "    + F1-score = 2x (prc x rec) / (prc x rec)\n",
    "    + UTILIZAR: classification_report(y_test, yhat)\n",
    "- _Log loss_: usar método 'log_loss(y_test, yhat_prob)'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
